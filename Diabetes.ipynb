{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1e0oIR7IhfhojmEvL777zzpDOI3GgSLt7","authorship_tag":"ABX9TyOBZF1kWd/jhjGYd8E727tk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":35,"metadata":{"id":"Sr_dN8j52SgM","executionInfo":{"status":"ok","timestamp":1687098960624,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/Shareddrives/Project/NN course/diabetes.csv')\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJZaybYw2tOc","executionInfo":{"status":"ok","timestamp":1687097736267,"user_tz":-330,"elapsed":1915,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"23b53893-9ccf-4b3a-819b-dfee9899ab2c"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768, 8)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"iDIVIOi-2tRJ","executionInfo":{"status":"ok","timestamp":1687097744181,"user_tz":-330,"elapsed":30,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"9cd8feb5-fc80-4ea8-c2a0-43ce775a75c3"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Number of times pregnant  Plasma glucose concentration  \\\n","0                         6                           148   \n","1                         1                            85   \n","2                         8                           183   \n","3                         1                            89   \n","4                         0                           137   \n","\n","   Diastolic blood pressure  Triceps skin fold thickness  \\\n","0                        72                           35   \n","1                        66                           29   \n","2                        64                            0   \n","3                        66                           23   \n","4                        40                           35   \n","\n","   2-Hour serum insulin  Body mass index  Age     Class  \n","0                     0             33.6   50  positive  \n","1                     0             26.6   31  negative  \n","2                     0             23.3   32  positive  \n","3                    94             28.1   21  negative  \n","4                   168             43.1   33  positive  "],"text/html":["\n","  <div id=\"df-6a7a47ab-cf0e-4a4e-a051-2c6dfb98e565\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Number of times pregnant</th>\n","      <th>Plasma glucose concentration</th>\n","      <th>Diastolic blood pressure</th>\n","      <th>Triceps skin fold thickness</th>\n","      <th>2-Hour serum insulin</th>\n","      <th>Body mass index</th>\n","      <th>Age</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>50</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>31</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>32</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>21</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>33</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a7a47ab-cf0e-4a4e-a051-2c6dfb98e565')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6a7a47ab-cf0e-4a4e-a051-2c6dfb98e565 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6a7a47ab-cf0e-4a4e-a051-2c6dfb98e565');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CU5GvoR-2tTm","executionInfo":{"status":"ok","timestamp":1687097766657,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"515a8839-576d-4677-e574-7e9360dad89f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Number of times pregnant        0\n","Plasma glucose concentration    0\n","Diastolic blood pressure        0\n","Triceps skin fold thickness     0\n","2-Hour serum insulin            0\n","Body mass index                 0\n","Age                             0\n","Class                           0\n","dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df.Class.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQxhwah02tVp","executionInfo":{"status":"ok","timestamp":1687097783009,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"ea02a359-6b61-49cd-c29f-a6cf36a910d7"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["negative    500\n","positive    268\n","Name: Class, dtype: int64"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["x = df.iloc[:, :-1].values # cols, rows\n","y_str = list(df.iloc[:, -1])"],"metadata":{"id":"YYCQHAbi3gbm","executionInfo":{"status":"ok","timestamp":1687097953102,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["x.shape, len(y_str)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1JlDbOY3gZL","executionInfo":{"status":"ok","timestamp":1687097966804,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"09e3fe4f-3c34-43f2-d5e0-f3da1fd852a7"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((768, 7), 768)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["y_int = [1 if i == 'positive' else 0 for i in y_str]"],"metadata":{"id":"kT987qwP3gWE","executionInfo":{"status":"ok","timestamp":1687098164065,"user_tz":-330,"elapsed":481,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["y_int.count(0), y_int.count(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4gPLqV53gTN","executionInfo":{"status":"ok","timestamp":1687098193764,"user_tz":-330,"elapsed":33,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"44a080f9-86c3-4e38-cb66-d040e567f757"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 268)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["y = np.array(y_int, dtype='float64')"],"metadata":{"id":"0rzy5s6J3gQ9","executionInfo":{"status":"ok","timestamp":1687098258333,"user_tz":-330,"elapsed":33,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbrSTbZl3gO5","executionInfo":{"status":"ok","timestamp":1687098276114,"user_tz":-330,"elapsed":541,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"c0f2a7d9-e3d5-4f40-c946-d497e8b6e3e8"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n","       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n","       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n","       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n","       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n","       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n","       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n","       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n","       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n","       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n","       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n","       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n","       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n","       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n","       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n","       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n","       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n","       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n","       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n","       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n","       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n","       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n","       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n","       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n","       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n","       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n","       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n","       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n","       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n","       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n","       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n","       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n","       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n","       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n","       0., 1., 0.])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["sc = StandardScaler()\n","x = sc.fit_transform(x)\n"],"metadata":{"id":"7Pz4uaM03gMi","executionInfo":{"status":"ok","timestamp":1687098585261,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["x = torch.tensor(x)\n","# Change y into 2 dim for BCE\n","\n","y = torch.tensor(y).unsqueeze(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6J1C_ET93gKH","executionInfo":{"status":"ok","timestamp":1687098740815,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"8a9456f1-758a-4b8e-d733-333138155b29"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-30-6f39ad84bfa5>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  x = torch.tensor(x)\n","<ipython-input-30-6f39ad84bfa5>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(y).unsqueeze(1)\n"]}]},{"cell_type":"code","source":["x.shape, y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45uPNd1W3gHn","executionInfo":{"status":"ok","timestamp":1687098740815,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"0d2b2a8a-cd96-44b3-acbf-b848b6c5b16a"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([768, 7]), torch.Size([768, 1]))"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# Custom dataset pytorch\n","\n","class Dataset(Dataset):\n","\n","  def __init__(self, x, y):\n","    self.x = x\n","    self.y = y\n","\n","\n","  def __getitem__(self, index):\n","    return self.x[index], self.y[index]\n","\n","  def __len__(self):\n","    return len(self.x)\n","\n"],"metadata":{"id":"InBkHGw33gFK","executionInfo":{"status":"ok","timestamp":1687098890753,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["dataset = Dataset(x, y)"],"metadata":{"id":"2oTzjF0H3gCO","executionInfo":{"status":"ok","timestamp":1687098913606,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PL-RdZJj2tZV","executionInfo":{"status":"ok","timestamp":1687098924358,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"548c40e2-c3bc-4a28-add2-73e8b8f023a1"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# Load data using dataloader\n","train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=True)"],"metadata":{"id":"Jk32PsZh2tcG","executionInfo":{"status":"ok","timestamp":1687099051928,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["train_loader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6n9fJNlK2teg","executionInfo":{"status":"ok","timestamp":1687099057993,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"cd1422fb-184e-4f28-8e34-a15f54da2f85"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x7f0958d9fb80>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["print(f'There are {len(train_loader)} batches in the dataset')\n","\n","for (x, y) in train_loader:\n","  print('For one iteration (batch), there are: ')\n","  print(f'Data: {x.shape}')\n","  print(f'Labels: {y.shape}')\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_b1CB0jE8REZ","executionInfo":{"status":"ok","timestamp":1687099183932,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"c7c6d59f-b9f8-4f78-fff0-815a27c60322"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 24 batches in the dataset\n","For one iteration (batch), there are: \n","Data: torch.Size([32, 7])\n","Labels: torch.Size([32, 1])\n"]}]},{"cell_type":"code","source":["# 7->5->4->3->1 layered NN\n","# Hidden tanh, output sigmoid\n","class Model(nn.Module):\n","\n","  def __init__(self, input_features, output_features):\n","    super(Model, self).__init__()\n","    self.fc1 = nn.Linear(input_features, 5)\n","    self.fc2 = nn.Linear(5, 4)\n","    self.fc3 = nn.Linear(4, 3)\n","    self.fc4 = nn.Linear(3, output_features)\n","    self.sigmoid = nn.Sigmoid()\n","    self.tanh = nn.Tanh()\n","\n","  def forward(self, x):\n","    out = self.fc1(x)\n","    out = self.tanh(out)\n","    out = self.fc2(out)\n","    out = self.tanh(out)\n","    out = self.fc3(out)\n","    out = self.tanh(out)\n","    out = self.fc4(out)\n","    out = self.sigmoid(out)\n","    return out"],"metadata":{"id":"VtZMZNy28RBl","executionInfo":{"status":"ok","timestamp":1687099798481,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# NN\n","net = Model(7, 1)\n","# Loss\n","criterion = nn.BCELoss(size_average=True)\n","# Optimizer\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n"],"metadata":{"id":"VsIXyR238Q_w","executionInfo":{"status":"ok","timestamp":1687099968681,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# Train network\n","epochs = 200\n","for epoch in range(epochs):\n","  for inputs, labels in train_loader:\n","    inputs = inputs.float()\n","    labels = labels.float()\n","    # forward prop\n","    outputs = net(inputs) # it is same as net.forward(inputs)\n","    # loss calc\n","    loss = criterion(outputs, labels)\n","    # clear the gradient buffer (other frameworks do this automatically)\n","    optimizer.zero_grad()\n","    # back prop\n","    loss.backward()\n","    # update weights\n","    optimizer.step()\n","  # accuracy calculation\n","  output = (outputs > 0.5).float()\n","  accuracy = (output == labels).float().mean()\n","  # print statistics\n","  print('Epoch {} / {}, Loss: {:.3f}, Accuracy: {:.3f}'.format(epoch + 1, epochs, loss, accuracy))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJULsuId8Q9c","executionInfo":{"status":"ok","timestamp":1687100582506,"user_tz":-330,"elapsed":8043,"user":{"displayName":"Sharath S Hebbar","userId":"12626432486155971149"}},"outputId":"8fe29292-8f88-4b05-8107-8cfe7d21bf41"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 / 200, Loss: 0.507, Accuracy: 0.719\n","Epoch 2 / 200, Loss: 0.547, Accuracy: 0.719\n","Epoch 3 / 200, Loss: 0.467, Accuracy: 0.750\n","Epoch 4 / 200, Loss: 0.498, Accuracy: 0.750\n","Epoch 5 / 200, Loss: 0.589, Accuracy: 0.781\n","Epoch 6 / 200, Loss: 0.634, Accuracy: 0.688\n","Epoch 7 / 200, Loss: 0.373, Accuracy: 0.812\n","Epoch 8 / 200, Loss: 0.470, Accuracy: 0.781\n","Epoch 9 / 200, Loss: 0.393, Accuracy: 0.844\n","Epoch 10 / 200, Loss: 0.382, Accuracy: 0.875\n","Epoch 11 / 200, Loss: 0.525, Accuracy: 0.719\n","Epoch 12 / 200, Loss: 0.395, Accuracy: 0.844\n","Epoch 13 / 200, Loss: 0.470, Accuracy: 0.719\n","Epoch 14 / 200, Loss: 0.393, Accuracy: 0.875\n","Epoch 15 / 200, Loss: 0.286, Accuracy: 0.938\n","Epoch 16 / 200, Loss: 0.477, Accuracy: 0.750\n","Epoch 17 / 200, Loss: 0.501, Accuracy: 0.688\n","Epoch 18 / 200, Loss: 0.446, Accuracy: 0.719\n","Epoch 19 / 200, Loss: 0.364, Accuracy: 0.875\n","Epoch 20 / 200, Loss: 0.410, Accuracy: 0.750\n","Epoch 21 / 200, Loss: 0.647, Accuracy: 0.750\n","Epoch 22 / 200, Loss: 0.407, Accuracy: 0.750\n","Epoch 23 / 200, Loss: 0.452, Accuracy: 0.750\n","Epoch 24 / 200, Loss: 0.429, Accuracy: 0.812\n","Epoch 25 / 200, Loss: 0.683, Accuracy: 0.688\n","Epoch 26 / 200, Loss: 0.526, Accuracy: 0.750\n","Epoch 27 / 200, Loss: 0.502, Accuracy: 0.688\n","Epoch 28 / 200, Loss: 0.515, Accuracy: 0.688\n","Epoch 29 / 200, Loss: 0.385, Accuracy: 0.844\n","Epoch 30 / 200, Loss: 0.481, Accuracy: 0.719\n","Epoch 31 / 200, Loss: 0.500, Accuracy: 0.656\n","Epoch 32 / 200, Loss: 0.451, Accuracy: 0.750\n","Epoch 33 / 200, Loss: 0.353, Accuracy: 0.844\n","Epoch 34 / 200, Loss: 0.538, Accuracy: 0.656\n","Epoch 35 / 200, Loss: 0.481, Accuracy: 0.719\n","Epoch 36 / 200, Loss: 0.418, Accuracy: 0.719\n","Epoch 37 / 200, Loss: 0.266, Accuracy: 0.875\n","Epoch 38 / 200, Loss: 0.500, Accuracy: 0.656\n","Epoch 39 / 200, Loss: 0.521, Accuracy: 0.719\n","Epoch 40 / 200, Loss: 0.382, Accuracy: 0.812\n","Epoch 41 / 200, Loss: 0.334, Accuracy: 0.844\n","Epoch 42 / 200, Loss: 0.496, Accuracy: 0.781\n","Epoch 43 / 200, Loss: 0.410, Accuracy: 0.844\n","Epoch 44 / 200, Loss: 0.633, Accuracy: 0.688\n","Epoch 45 / 200, Loss: 0.506, Accuracy: 0.781\n","Epoch 46 / 200, Loss: 0.440, Accuracy: 0.688\n","Epoch 47 / 200, Loss: 0.487, Accuracy: 0.688\n","Epoch 48 / 200, Loss: 0.529, Accuracy: 0.688\n","Epoch 49 / 200, Loss: 0.415, Accuracy: 0.812\n","Epoch 50 / 200, Loss: 0.397, Accuracy: 0.844\n","Epoch 51 / 200, Loss: 0.432, Accuracy: 0.812\n","Epoch 52 / 200, Loss: 0.569, Accuracy: 0.719\n","Epoch 53 / 200, Loss: 0.409, Accuracy: 0.750\n","Epoch 54 / 200, Loss: 0.437, Accuracy: 0.781\n","Epoch 55 / 200, Loss: 0.382, Accuracy: 0.875\n","Epoch 56 / 200, Loss: 0.340, Accuracy: 0.812\n","Epoch 57 / 200, Loss: 0.480, Accuracy: 0.750\n","Epoch 58 / 200, Loss: 0.611, Accuracy: 0.656\n","Epoch 59 / 200, Loss: 0.304, Accuracy: 0.875\n","Epoch 60 / 200, Loss: 0.470, Accuracy: 0.844\n","Epoch 61 / 200, Loss: 0.555, Accuracy: 0.625\n","Epoch 62 / 200, Loss: 0.356, Accuracy: 0.781\n","Epoch 63 / 200, Loss: 0.380, Accuracy: 0.875\n","Epoch 64 / 200, Loss: 0.353, Accuracy: 0.906\n","Epoch 65 / 200, Loss: 0.445, Accuracy: 0.750\n","Epoch 66 / 200, Loss: 0.462, Accuracy: 0.750\n","Epoch 67 / 200, Loss: 0.339, Accuracy: 0.781\n","Epoch 68 / 200, Loss: 0.328, Accuracy: 0.844\n","Epoch 69 / 200, Loss: 0.398, Accuracy: 0.875\n","Epoch 70 / 200, Loss: 0.587, Accuracy: 0.625\n","Epoch 71 / 200, Loss: 0.511, Accuracy: 0.750\n","Epoch 72 / 200, Loss: 0.430, Accuracy: 0.844\n","Epoch 73 / 200, Loss: 0.414, Accuracy: 0.781\n","Epoch 74 / 200, Loss: 0.401, Accuracy: 0.781\n","Epoch 75 / 200, Loss: 0.488, Accuracy: 0.812\n","Epoch 76 / 200, Loss: 0.415, Accuracy: 0.781\n","Epoch 77 / 200, Loss: 0.531, Accuracy: 0.750\n","Epoch 78 / 200, Loss: 0.651, Accuracy: 0.750\n","Epoch 79 / 200, Loss: 0.469, Accuracy: 0.812\n","Epoch 80 / 200, Loss: 0.256, Accuracy: 0.938\n","Epoch 81 / 200, Loss: 0.324, Accuracy: 0.812\n","Epoch 82 / 200, Loss: 0.472, Accuracy: 0.750\n","Epoch 83 / 200, Loss: 0.418, Accuracy: 0.812\n","Epoch 84 / 200, Loss: 0.561, Accuracy: 0.688\n","Epoch 85 / 200, Loss: 0.358, Accuracy: 0.844\n","Epoch 86 / 200, Loss: 0.515, Accuracy: 0.781\n","Epoch 87 / 200, Loss: 0.413, Accuracy: 0.750\n","Epoch 88 / 200, Loss: 0.427, Accuracy: 0.750\n","Epoch 89 / 200, Loss: 0.412, Accuracy: 0.781\n","Epoch 90 / 200, Loss: 0.262, Accuracy: 0.906\n","Epoch 91 / 200, Loss: 0.547, Accuracy: 0.688\n","Epoch 92 / 200, Loss: 0.486, Accuracy: 0.688\n","Epoch 93 / 200, Loss: 0.416, Accuracy: 0.781\n","Epoch 94 / 200, Loss: 0.299, Accuracy: 0.875\n","Epoch 95 / 200, Loss: 0.451, Accuracy: 0.719\n","Epoch 96 / 200, Loss: 0.514, Accuracy: 0.719\n","Epoch 97 / 200, Loss: 0.430, Accuracy: 0.781\n","Epoch 98 / 200, Loss: 0.379, Accuracy: 0.812\n","Epoch 99 / 200, Loss: 0.398, Accuracy: 0.812\n","Epoch 100 / 200, Loss: 0.419, Accuracy: 0.812\n","Epoch 101 / 200, Loss: 0.381, Accuracy: 0.875\n","Epoch 102 / 200, Loss: 0.454, Accuracy: 0.750\n","Epoch 103 / 200, Loss: 0.311, Accuracy: 0.844\n","Epoch 104 / 200, Loss: 0.451, Accuracy: 0.844\n","Epoch 105 / 200, Loss: 0.446, Accuracy: 0.750\n","Epoch 106 / 200, Loss: 0.306, Accuracy: 0.844\n","Epoch 107 / 200, Loss: 0.551, Accuracy: 0.750\n","Epoch 108 / 200, Loss: 0.467, Accuracy: 0.781\n","Epoch 109 / 200, Loss: 0.357, Accuracy: 0.844\n","Epoch 110 / 200, Loss: 0.562, Accuracy: 0.625\n","Epoch 111 / 200, Loss: 0.477, Accuracy: 0.750\n","Epoch 112 / 200, Loss: 0.387, Accuracy: 0.812\n","Epoch 113 / 200, Loss: 0.410, Accuracy: 0.844\n","Epoch 114 / 200, Loss: 0.450, Accuracy: 0.812\n","Epoch 115 / 200, Loss: 0.378, Accuracy: 0.844\n","Epoch 116 / 200, Loss: 0.420, Accuracy: 0.812\n","Epoch 117 / 200, Loss: 0.401, Accuracy: 0.781\n","Epoch 118 / 200, Loss: 0.265, Accuracy: 0.906\n","Epoch 119 / 200, Loss: 0.507, Accuracy: 0.719\n","Epoch 120 / 200, Loss: 0.442, Accuracy: 0.781\n","Epoch 121 / 200, Loss: 0.262, Accuracy: 0.906\n","Epoch 122 / 200, Loss: 0.319, Accuracy: 0.844\n","Epoch 123 / 200, Loss: 0.416, Accuracy: 0.812\n","Epoch 124 / 200, Loss: 0.494, Accuracy: 0.750\n","Epoch 125 / 200, Loss: 0.343, Accuracy: 0.844\n","Epoch 126 / 200, Loss: 0.446, Accuracy: 0.812\n","Epoch 127 / 200, Loss: 0.539, Accuracy: 0.719\n","Epoch 128 / 200, Loss: 0.406, Accuracy: 0.812\n","Epoch 129 / 200, Loss: 0.586, Accuracy: 0.656\n","Epoch 130 / 200, Loss: 0.305, Accuracy: 0.875\n","Epoch 131 / 200, Loss: 0.331, Accuracy: 0.875\n","Epoch 132 / 200, Loss: 0.433, Accuracy: 0.844\n","Epoch 133 / 200, Loss: 0.398, Accuracy: 0.781\n","Epoch 134 / 200, Loss: 0.263, Accuracy: 0.906\n","Epoch 135 / 200, Loss: 0.515, Accuracy: 0.750\n","Epoch 136 / 200, Loss: 0.545, Accuracy: 0.750\n","Epoch 137 / 200, Loss: 0.397, Accuracy: 0.844\n","Epoch 138 / 200, Loss: 0.349, Accuracy: 0.812\n","Epoch 139 / 200, Loss: 0.511, Accuracy: 0.719\n","Epoch 140 / 200, Loss: 0.606, Accuracy: 0.656\n","Epoch 141 / 200, Loss: 0.424, Accuracy: 0.750\n","Epoch 142 / 200, Loss: 0.187, Accuracy: 0.969\n","Epoch 143 / 200, Loss: 0.395, Accuracy: 0.750\n","Epoch 144 / 200, Loss: 0.393, Accuracy: 0.844\n","Epoch 145 / 200, Loss: 0.343, Accuracy: 0.875\n","Epoch 146 / 200, Loss: 0.375, Accuracy: 0.781\n","Epoch 147 / 200, Loss: 0.377, Accuracy: 0.812\n","Epoch 148 / 200, Loss: 0.428, Accuracy: 0.844\n","Epoch 149 / 200, Loss: 0.433, Accuracy: 0.812\n","Epoch 150 / 200, Loss: 0.537, Accuracy: 0.781\n","Epoch 151 / 200, Loss: 0.496, Accuracy: 0.719\n","Epoch 152 / 200, Loss: 0.486, Accuracy: 0.750\n","Epoch 153 / 200, Loss: 0.290, Accuracy: 0.875\n","Epoch 154 / 200, Loss: 0.601, Accuracy: 0.656\n","Epoch 155 / 200, Loss: 0.470, Accuracy: 0.750\n","Epoch 156 / 200, Loss: 0.509, Accuracy: 0.719\n","Epoch 157 / 200, Loss: 0.415, Accuracy: 0.812\n","Epoch 158 / 200, Loss: 0.326, Accuracy: 0.875\n","Epoch 159 / 200, Loss: 0.521, Accuracy: 0.750\n","Epoch 160 / 200, Loss: 0.492, Accuracy: 0.719\n","Epoch 161 / 200, Loss: 0.412, Accuracy: 0.719\n","Epoch 162 / 200, Loss: 0.344, Accuracy: 0.781\n","Epoch 163 / 200, Loss: 0.540, Accuracy: 0.688\n","Epoch 164 / 200, Loss: 0.498, Accuracy: 0.781\n","Epoch 165 / 200, Loss: 0.348, Accuracy: 0.844\n","Epoch 166 / 200, Loss: 0.487, Accuracy: 0.844\n","Epoch 167 / 200, Loss: 0.406, Accuracy: 0.844\n","Epoch 168 / 200, Loss: 0.337, Accuracy: 0.844\n","Epoch 169 / 200, Loss: 0.324, Accuracy: 0.938\n","Epoch 170 / 200, Loss: 0.413, Accuracy: 0.844\n","Epoch 171 / 200, Loss: 0.497, Accuracy: 0.688\n","Epoch 172 / 200, Loss: 0.367, Accuracy: 0.875\n","Epoch 173 / 200, Loss: 0.441, Accuracy: 0.750\n","Epoch 174 / 200, Loss: 0.362, Accuracy: 0.844\n","Epoch 175 / 200, Loss: 0.525, Accuracy: 0.750\n","Epoch 176 / 200, Loss: 0.422, Accuracy: 0.781\n","Epoch 177 / 200, Loss: 0.437, Accuracy: 0.781\n","Epoch 178 / 200, Loss: 0.503, Accuracy: 0.781\n","Epoch 179 / 200, Loss: 0.484, Accuracy: 0.781\n","Epoch 180 / 200, Loss: 0.350, Accuracy: 0.844\n","Epoch 181 / 200, Loss: 0.518, Accuracy: 0.781\n","Epoch 182 / 200, Loss: 0.448, Accuracy: 0.844\n","Epoch 183 / 200, Loss: 0.445, Accuracy: 0.844\n","Epoch 184 / 200, Loss: 0.440, Accuracy: 0.781\n","Epoch 185 / 200, Loss: 0.339, Accuracy: 0.844\n","Epoch 186 / 200, Loss: 0.428, Accuracy: 0.844\n","Epoch 187 / 200, Loss: 0.312, Accuracy: 0.844\n","Epoch 188 / 200, Loss: 0.648, Accuracy: 0.750\n","Epoch 189 / 200, Loss: 0.521, Accuracy: 0.719\n","Epoch 190 / 200, Loss: 0.512, Accuracy: 0.750\n","Epoch 191 / 200, Loss: 0.282, Accuracy: 0.875\n","Epoch 192 / 200, Loss: 0.488, Accuracy: 0.750\n","Epoch 193 / 200, Loss: 0.364, Accuracy: 0.812\n","Epoch 194 / 200, Loss: 0.302, Accuracy: 0.875\n","Epoch 195 / 200, Loss: 0.478, Accuracy: 0.781\n","Epoch 196 / 200, Loss: 0.288, Accuracy: 0.906\n","Epoch 197 / 200, Loss: 0.382, Accuracy: 0.875\n","Epoch 198 / 200, Loss: 0.419, Accuracy: 0.781\n","Epoch 199 / 200, Loss: 0.442, Accuracy: 0.781\n","Epoch 200 / 200, Loss: 0.492, Accuracy: 0.844\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nQGZV2uC8Q7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wFxkqc8_8Q50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0vzgDgFR8Q3u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xyc986Kq8Q1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XyWKSNZv8J3p"},"execution_count":null,"outputs":[]}]}